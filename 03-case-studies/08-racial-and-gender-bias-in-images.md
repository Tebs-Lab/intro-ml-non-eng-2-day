# Racial and Gender Bias by Profession in Image Generation

Source: [https://www.bloomberg.com/graphics/2023-generative-ai-bias/](https://www.bloomberg.com/graphics/2023-generative-ai-bias/)

Bloomberg prompted Stable Diffusion to generate pictures of people with various professions, then categorized the output based on skin tone and perceived gender. They found that:

> The analysis found that image sets generated for every high-paying job were dominated by subjects with lighter skin tones, while subjects with darker skin tones were more commonly generated by prompts like “fast-food worker” and “social worker.”

![](assets/bloombergSkinTone.png)

and

> For each image depicting a perceived woman, Stable Diffusion generated almost three times as many images of perceived men. Most occupations in the dataset were dominated by men, except for low-paying jobs like housekeeper and cashier.

![](assets/bloombergPercievedGender.png)

## Additional Questions

* Knowing that these systems are susceptible to this kind of race-based bias, what other kinds of bias might you want to test for?
