# Amazon's Resume Scanner

In 2018, Amazon [shut down a machine learning system it had built to scan resumes](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G). Because the system was discriminating against women.

Some key facts:

* The algorithm was meant to take a resume and decide if that person should get a phone screen.
* The algorithm was trained with historical data from Amazon's existing workforce.
* The algorithm was not explicitly given any demographic information, only the raw text of each resume.
* The simple appearance of the word "woman" in a resume significantly reduced the chance that the algorithm would suggest a phone screen, but even when no obvious demographic information was included in the text, the algorithm still seemed to penalized women.

### Additional Questions

1. With regards to the training data for this system...
    * Is it labeled? If so, how and by whom?
    * Who collected it, how, and when?


